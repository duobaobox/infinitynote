/**
 * ç¡…åŸºæµåŠ¨æä¾›å•†å®ç°
 * ç»§æ‰¿BaseAIProviderï¼Œæä¾›ç¡…åŸºæµåŠ¨ç‰¹å®šçš„å®ç°
 * ä½¿ç”¨OpenAIå…¼å®¹API
 */

import { BaseAIProvider } from "./BaseAIProvider";
import type {
  AIProviderConfig,
  RequestBodyBuilder,
  ResponseParser,
} from "./BaseAIProvider";
import type { AIGenerationOptions } from "../../types/ai";

/**
 * ç¡…åŸºæµåŠ¨è¯·æ±‚ä½“æ„å»ºå™¨
 * ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
 */
class SiliconFlowRequestBuilder implements RequestBodyBuilder {
  buildRequestBody(options: AIGenerationOptions): any {
    // ç›´æ¥ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹åç§°ï¼Œä¸åšæ ¡éªŒ
    const modelName = options.model || "deepseek-llm-67b-chat";

    const requestBody: any = {
      model: modelName,
      messages: [
        {
          role: "user",
          content: options.prompt,
        },
      ],
      stream: options.stream ?? true,
    };

    if (options.temperature !== undefined) {
      requestBody.temperature = options.temperature;
    }

    if (options.maxTokens) {
      requestBody.max_tokens = options.maxTokens;
    }

    console.log(
      `ğŸš€ [SiliconFlow] æ„å»ºè¯·æ±‚ä½“:`,
      JSON.stringify(requestBody, null, 2)
    );
    return requestBody;
  }
}

/**
 * ç¡…åŸºæµåŠ¨å“åº”è§£æå™¨
 * ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼
 */
class SiliconFlowResponseParser implements ResponseParser {
  extractContentFromChunk(chunk: string): string {
    try {
      const lines = chunk
        .split("\n")
        .filter((line) => line.startsWith("data: "));

      let content = "";
      for (const line of lines) {
        const data = line.slice(6);
        if (data === "[DONE]") continue;

        try {
          const parsed = JSON.parse(data);
          const deltaContent = parsed.choices?.[0]?.delta?.content;
          if (deltaContent) {
            content += deltaContent;
            console.log(
              `ğŸ“ [SiliconFlow] æå–åˆ°å†…å®¹:`,
              deltaContent.substring(0, 100)
            );
          }
        } catch (parseError) {
          continue;
        }
      }
      return content;
    } catch (error) {
      console.warn("ç¡…åŸºæµåŠ¨å†…å®¹æå–å¤±è´¥:", error);
      return "";
    }
  }

  extractThinkingFromChunk(_chunk: string): string | null {
    // ç¡…åŸºæµåŠ¨ä½œä¸ºä»£ç†æœåŠ¡ï¼Œä¸æ”¯æŒæ€ç»´é“¾
    return null;
  }

  isStreamComplete(chunk: string): boolean {
    return chunk.includes("data: [DONE]");
  }
}

/**
 * ç¡…åŸºæµåŠ¨æä¾›å•†
 * ç»§æ‰¿BaseAIProviderï¼Œå®ç°ç¡…åŸºæµåŠ¨ç‰¹å®šçš„åŠŸèƒ½
 */
export class SiliconFlowProvider extends BaseAIProvider {
  readonly name = "siliconflow";

  protected readonly config: AIProviderConfig = {
    apiEndpoint: "https://api.siliconflow.cn/v1/chat/completions",
    defaultModel: "deepseek-llm-67b-chat",
    supportedModels: [
      "deepseek-llm-67b-chat",
      "qwen-72b-chat",
      "internlm2_5-7b-chat",
      "yi-large",
    ],
    supportsStreaming: true,
    supportsThinking: false,
  };

  protected readonly requestBuilder = new SiliconFlowRequestBuilder();
  protected readonly responseParser = new SiliconFlowResponseParser();
}
