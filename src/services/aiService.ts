/**
 * AI æœåŠ¡å±‚
 * ç»Ÿä¸€ç®¡ç† AI æä¾›å•†å’Œç”Ÿæˆé€»è¾‘
 */

import type {
  AIProvider,
  AIGenerationOptions,
  AISettings,
  ZhipuAPIResponse,
  AICustomProperties,
} from "../types/ai";
import { AIGenerationPhase } from "../types/ai";
import { markdownConverter } from "../utils/markdownConverter";
import { dbOperations, type AIConfigDB } from "../utils/db";
import { aiDebugCollector } from "../utils/aiDebugCollector";

/**
 * å®‰å…¨ç®¡ç†å™¨ - å¤„ç†APIå¯†é’¥å­˜å‚¨ï¼ˆä½¿ç”¨IndexedDBï¼‰
 */
class SecurityManager {
  private static instance: SecurityManager;

  private constructor() {}

  static getInstance(): SecurityManager {
    if (!SecurityManager.instance) {
      SecurityManager.instance = new SecurityManager();
    }
    return SecurityManager.instance;
  }

  /**
   * å®‰å…¨å­˜å‚¨APIå¯†é’¥ï¼ˆä½¿ç”¨IndexedDBï¼‰
   */
  async setAPIKey(provider: string, key: string): Promise<void> {
    try {
      // ç®€å•çš„æœ¬åœ°åŠ å¯†ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å¼ºçš„åŠ å¯†ï¼‰
      const encrypted = btoa(key);
      const config: AIConfigDB = {
        id: `api_key_${provider}`,
        type: "api_key",
        provider,
        value: encrypted,
        encrypted: true,
        createdAt: new Date(),
        updatedAt: new Date(),
      };
      await dbOperations.saveAIConfig(config);
    } catch (error) {
      console.error("å­˜å‚¨APIå¯†é’¥å¤±è´¥:", error);
      throw new Error("å¯†é’¥å­˜å‚¨å¤±è´¥");
    }
  }

  /**
   * å®‰å…¨è·å–APIå¯†é’¥ï¼ˆä»IndexedDBï¼‰
   */
  async getAPIKey(provider: string): Promise<string | null> {
    try {
      const config = await dbOperations.getAIConfig(`api_key_${provider}`);
      if (!config || !config.value) return null;
      return atob(config.value);
    } catch (error) {
      console.error("è·å–APIå¯†é’¥å¤±è´¥:", error);
      return null;
    }
  }

  /**
   * éªŒè¯APIå¯†é’¥æ ¼å¼
   */
  validateAPIKey(provider: string, key: string): boolean {
    const patterns = {
      zhipu: /^[a-zA-Z0-9]{32,}$/,
      openai: /^sk-[a-zA-Z0-9]{48}$/,
      deepseek: /^sk-[a-zA-Z0-9]{32,}$/, // DeepSeek APIå¯†é’¥æ ¼å¼
      alibaba: /^sk-[a-zA-Z0-9]{20,}$/, // é˜¿é‡Œç™¾ç‚¼ APIå¯†é’¥æ ¼å¼
      siliconflow: /^sk-[a-zA-Z0-9]{32,}$/, // ç¡…åŸºæµåŠ¨ APIå¯†é’¥æ ¼å¼
      anthropic: /^sk-ant-api03-[a-zA-Z0-9\-_]{93}$/, // Anthropic APIå¯†é’¥æ ¼å¼
    };

    const pattern = patterns[provider as keyof typeof patterns];
    return pattern ? pattern.test(key) : key.length > 20; // é»˜è®¤éªŒè¯é•¿åº¦
  }

  /**
   * æ¸…ç†APIå¯†é’¥ï¼ˆä»IndexedDBï¼‰
   */
  async clearAPIKey(provider: string): Promise<void> {
    try {
      await dbOperations.deleteAIConfig(`api_key_${provider}`);
    } catch (error) {
      console.error("æ¸…ç†APIå¯†é’¥å¤±è´¥:", error);
    }
  }
}

/**
 * æ™ºè°±AIæä¾›å•†å®ç°
 */
class ZhipuAIProvider implements AIProvider {
  name = "zhipu";
  supportedModels = ["glm-4", "glm-4-plus"];
  supportsStreaming = true;
  supportsThinking = true;

  async generateContent(options: AIGenerationOptions): Promise<void> {
    const securityManager = SecurityManager.getInstance();
    const apiKey = await securityManager.getAPIKey("zhipu");

    if (!apiKey) {
      throw new Error("æ™ºè°±AI APIå¯†é’¥æœªé…ç½®");
    }

    // å¼€å§‹è°ƒè¯•ä¼šè¯
    const debugSessionId = aiDebugCollector.startSession(options);
    aiDebugCollector.updateSessionProvider(debugSessionId, "zhipu");

    const abortController = new AbortController();

    try {
      const response = await fetch(
        "https://open.bigmodel.cn/api/paas/v4/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: options.model || "glm-4",
            messages: [
              {
                role: "user",
                content: options.prompt,
              },
            ],
            stream: true,
            temperature: options.temperature || 0.7,
            max_tokens: options.maxTokens || 1000,
          }),
          signal: abortController.signal,
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        const error = new Error(
          `æ™ºè°±AI APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}. ${errorText}`
        );
        aiDebugCollector.recordError(debugSessionId, error, {
          status: response.status,
          statusText: response.statusText,
          responseText: errorText,
        });
        throw error;
      }

      await this.handleStreamResponse(
        response,
        options,
        abortController,
        debugSessionId
      );
    } catch (error) {
      if (error instanceof Error && error.name === "AbortError") {
        aiDebugCollector.cancelSession(debugSessionId);
        console.log("æ™ºè°±AIç”Ÿæˆå·²è¢«ä¸­æ­¢");
        return; // æ­£å¸¸ä¸­æ­¢ï¼Œä¸æŠ›å‡ºé”™è¯¯
      }

      console.error("æ™ºè°±AI APIè°ƒç”¨å¤±è´¥:", error);
      aiDebugCollector.recordError(debugSessionId, error as Error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  private async handleStreamResponse(
    response: Response,
    options: AIGenerationOptions,
    abortController: AbortController,
    debugSessionId: string
  ): Promise<void> {
    const reader = response.body?.getReader();
    if (!reader) throw new Error("æ— æ³•è¯»å–å“åº”æµ");

    let fullContent = "";
    let fullMarkdown = "";
    const thinkingChain: any[] = [];
    let retryCount = 0;
    const maxRetries = 3;

    try {
      while (true) {
        if (abortController.signal.aborted) {
          break;
        }

        try {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = new TextDecoder().decode(value);
          const lines = chunk.split("\n").filter((line) => line.trim());

          for (const line of lines) {
            if (abortController.signal.aborted) {
              return;
            }

            if (line.startsWith("data: ")) {
              const data = line.slice(6);
              if (data === "[DONE]") continue;

              try {
                const parsed: ZhipuAPIResponse = JSON.parse(data);
                const deltaContent = parsed.choices?.[0]?.delta?.content || "";

                if (deltaContent) {
                  fullMarkdown += deltaContent;
                  // å®æ—¶è½¬æ¢ä¸ºHTML
                  fullContent =
                    markdownConverter.convertStreamChunk(fullMarkdown);
                  options.onStream?.(fullContent);
                }

                // è§£ææ€ç»´é“¾ï¼ˆå¦‚æœæ”¯æŒï¼‰
                const thinking = parsed.choices?.[0]?.delta?.thinking;
                if (thinking) {
                  thinkingChain.push({
                    id: `step_${thinkingChain.length + 1}`,
                    content: thinking,
                    timestamp: Date.now(),
                  });
                }

                // è®°å½•è°ƒè¯•æ•°æ®
                aiDebugCollector.recordStreamChunk(
                  debugSessionId,
                  parsed,
                  deltaContent,
                  thinking
                );

                retryCount = 0; // é‡ç½®é‡è¯•è®¡æ•°
              } catch (parseError) {
                console.warn(
                  "è§£æå“åº”æ•°æ®å¤±è´¥:",
                  parseError,
                  "åŸå§‹æ•°æ®:",
                  data
                );
                retryCount++;
                if (retryCount > maxRetries) {
                  throw new Error("è¿ç»­è§£æå¤±è´¥ï¼Œä¸­æ­¢ç”Ÿæˆ");
                }
              }
            }
          }
        } catch (readError) {
          if (readError instanceof Error && readError.name === "AbortError") {
            return;
          }
          console.error("è¯»å–æµæ•°æ®å¤±è´¥:", readError);
          retryCount++;
          if (retryCount > maxRetries) {
            throw readError;
          }
          // çŸ­æš‚å»¶è¿Ÿåç»§ç»­
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      }

      if (!abortController.signal.aborted) {
        // æœ€ç»ˆè½¬æ¢
        const finalHTML = markdownConverter.convertComplete(fullMarkdown);

        // æ„é€ AIæ•°æ®
        const aiData: AICustomProperties["ai"] = {
          generated: true,
          model: options.model || "deepseek-reasoner",
          provider: "deepseek",
          generatedAt: new Date().toISOString(),
          prompt: options.prompt,
          requestId: `req_${Date.now()}`,
          showThinking: true,
          thinkingCollapsed: true,
          isStreaming: false,
          originalMarkdown: fullMarkdown,
        };

        if (thinkingChain.length > 0) {
          aiData.thinkingChain = {
            steps: thinkingChain,
            summary: `é€šè¿‡${thinkingChain.length}æ­¥æ¨ç†å®Œæˆ`,
            totalSteps: thinkingChain.length,
          };
        }

        // è®°å½•è°ƒè¯•å®Œæˆæ•°æ®
        aiDebugCollector.completeSession(debugSessionId, finalHTML, aiData);

        options.onComplete?.(finalHTML, aiData);
      }
    } finally {
      reader.releaseLock();
    }
  }
}

/**
 * OpenAI æä¾›å•†å®ç°ï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰
 */
class OpenAIProvider implements AIProvider {
  name = "openai";
  supportedModels = ["gpt-4", "gpt-4o", "gpt-3.5-turbo"];
  supportsStreaming = true;
  supportsThinking = false; // OpenAI ä¸æ”¯æŒæ€ç»´é“¾æ˜¾ç¤º

  async generateContent(options: AIGenerationOptions): Promise<void> {
    const securityManager = SecurityManager.getInstance();
    const apiKey = await securityManager.getAPIKey("openai");

    if (!apiKey) {
      throw new Error("OpenAI APIå¯†é’¥æœªé…ç½®");
    }

    // å¼€å§‹è°ƒè¯•ä¼šè¯
    const debugSessionId = aiDebugCollector.startSession(options);
    aiDebugCollector.updateSessionProvider(debugSessionId, "openai");

    const abortController = new AbortController();

    // åŸºç¡€å®ç°ï¼Œå¯ä»¥åç»­æ‰©å±•
    try {
      const response = await fetch(
        "https://api.openai.com/v1/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: options.model || "gpt-3.5-turbo",
            messages: [
              {
                role: "user",
                content: options.prompt,
              },
            ],
            stream: true,
            temperature: options.temperature || 0.7,
            max_tokens: options.maxTokens || 1000,
          }),
          signal: abortController.signal,
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        const error = new Error(
          `OpenAI APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}. ${errorText}`
        );
        aiDebugCollector.recordError(debugSessionId, error, {
          status: response.status,
          statusText: response.statusText,
          responseText: errorText,
        });
        throw error;
      }

      await this.handleStreamResponse(
        response,
        options,
        abortController,
        debugSessionId
      );
    } catch (error) {
      if (error instanceof Error && error.name === "AbortError") {
        aiDebugCollector.cancelSession(debugSessionId);
        console.log("OpenAIç”Ÿæˆå·²è¢«ä¸­æ­¢");
        return;
      }

      console.error("OpenAI APIè°ƒç”¨å¤±è´¥:", error);
      aiDebugCollector.recordError(debugSessionId, error as Error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  private async handleStreamResponse(
    response: Response,
    options: AIGenerationOptions,
    abortController: AbortController,
    debugSessionId: string
  ): Promise<void> {
    // ç®€åŒ–çš„æµå¼å¤„ç†ï¼ˆä¸æ™ºè°±AIç±»ä¼¼çš„é€»è¾‘ï¼‰
    const reader = response.body?.getReader();
    if (!reader) throw new Error("æ— æ³•è¯»å–å“åº”æµ");

    let fullMarkdown = "";
    let retryCount = 0;
    const maxRetries = 3;

    try {
      while (true) {
        if (abortController.signal.aborted) {
          break;
        }

        try {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = new TextDecoder().decode(value);
          // ç®€åŒ–çš„è§£æé€»è¾‘
          const content = this.extractContentFromChunk(chunk);
          if (content) {
            fullMarkdown += content;
            const html = markdownConverter.convertStreamChunk(fullMarkdown);
            options.onStream?.(html);

            // è®°å½•è°ƒè¯•æ•°æ®
            aiDebugCollector.recordStreamChunk(
              debugSessionId,
              { raw: chunk, type: "openai_chunk" },
              content
            );
          }

          retryCount = 0; // é‡ç½®é‡è¯•è®¡æ•°
        } catch (readError) {
          if (readError instanceof Error && readError.name === "AbortError") {
            return;
          }
          console.error("è¯»å–OpenAIæµæ•°æ®å¤±è´¥:", readError);
          retryCount++;
          if (retryCount > maxRetries) {
            throw readError;
          }
          // çŸ­æš‚å»¶è¿Ÿåç»§ç»­
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      }

      if (!abortController.signal.aborted) {
        const finalHTML = markdownConverter.convertComplete(fullMarkdown);
        const aiData: AICustomProperties["ai"] = {
          generated: true,
          model: options.model || "gpt-3.5-turbo",
          provider: "openai",
          generatedAt: new Date().toISOString(),
          prompt: options.prompt,
          requestId: `req_${Date.now()}`,
          showThinking: false, // OpenAIä¸æ”¯æŒæ€ç»´é“¾
          thinkingCollapsed: false,
          isStreaming: false,
          originalMarkdown: fullMarkdown,
        };

        // è®°å½•è°ƒè¯•å®Œæˆæ•°æ®
        aiDebugCollector.completeSession(debugSessionId, finalHTML, aiData);

        options.onComplete?.(finalHTML, aiData);
      }
    } finally {
      reader.releaseLock();
    }
  }

  private extractContentFromChunk(chunk: string): string {
    // ç®€åŒ–çš„å†…å®¹æå–é€»è¾‘ï¼Œå®é™…åº”è¯¥è§£æSSEæ ¼å¼
    // è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼ŒçœŸå®å®ç°éœ€è¦æ›´å¤æ‚çš„è§£æ
    try {
      const lines = chunk
        .split("\n")
        .filter((line) => line.startsWith("data: "));
      let content = "";
      for (const line of lines) {
        const data = line.slice(6);
        if (data === "[DONE]") continue;
        const parsed = JSON.parse(data);
        content += parsed.choices?.[0]?.delta?.content || "";
      }
      return content;
    } catch {
      return "";
    }
  }
}

/**
 * DeepSeek æä¾›å•†å®ç°
 */
class DeepSeekProvider implements AIProvider {
  name = "deepseek";
  supportedModels = ["deepseek-chat", "deepseek-reasoner"];
  supportsStreaming = true;
  supportsThinking = true; // DeepSeek-V3.1 æ”¯æŒæ€ç»´é“¾æ˜¾ç¤º

  async generateContent(options: AIGenerationOptions): Promise<void> {
    const securityManager = SecurityManager.getInstance();
    const apiKey = await securityManager.getAPIKey("deepseek");

    if (!apiKey) {
      throw new Error("DeepSeek APIå¯†é’¥æœªé…ç½®");
    }

    // å¼€å§‹è°ƒè¯•ä¼šè¯
    const debugSessionId = aiDebugCollector.startSession(options);
    aiDebugCollector.updateSessionProvider(debugSessionId, "deepseek");

    const abortController = new AbortController();

    try {
      const response = await fetch(
        "https://api.deepseek.com/v1/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: options.model || "deepseek-chat",
            messages: [
              {
                role: "user",
                content: options.prompt,
              },
            ],
            stream: true,
            temperature: options.temperature || 0.7,
            max_tokens: options.maxTokens || 2000,
          }),
          signal: abortController.signal,
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        const error = new Error(
          `DeepSeek APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}. ${errorText}`
        );
        aiDebugCollector.recordError(debugSessionId, error, {
          status: response.status,
          statusText: response.statusText,
          responseText: errorText,
        });
        throw error;
      }

      await this.handleStreamResponse(
        response,
        options,
        abortController,
        debugSessionId
      );
    } catch (error) {
      if (error instanceof Error && error.name === "AbortError") {
        aiDebugCollector.cancelSession(debugSessionId);
        console.log("DeepSeekç”Ÿæˆå·²è¢«ä¸­æ­¢");
        return; // æ­£å¸¸ä¸­æ­¢ï¼Œä¸æŠ›å‡ºé”™è¯¯
      }

      console.error("DeepSeek APIè°ƒç”¨å¤±è´¥:", error);
      aiDebugCollector.recordError(debugSessionId, error as Error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  private async handleStreamResponse(
    response: Response,
    options: AIGenerationOptions,
    abortController: AbortController,
    debugSessionId: string
  ): Promise<void> {
    const reader = response.body?.getReader();
    if (!reader) throw new Error("æ— æ³•è¯»å–å“åº”æµ");

    let fullContent = "";
    let fullMarkdown = "";
    let fullReasoning = "";
    const thinkingChain: any[] = [];
    let retryCount = 0;
    const maxRetries = 3;
    let hasStartedThinking = false; // æ ‡è®°æ˜¯å¦å·²å¼€å§‹æ€ç»´è¿‡ç¨‹
    let hasStartedAnswering = false; // æ ‡è®°æ˜¯å¦å·²å¼€å§‹å›å¤é˜¶æ®µ

    try {
      while (true) {
        if (abortController.signal.aborted) {
          break;
        }

        try {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = new TextDecoder().decode(value);
          const lines = chunk.split("\n").filter((line) => line.trim());

          for (const line of lines) {
            if (abortController.signal.aborted) {
              return;
            }

            if (line.startsWith("data: ")) {
              const data = line.slice(6);
              if (data === "[DONE]") continue;

              try {
                const parsed = JSON.parse(data);

                // æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
                if (options.model?.includes("reasoner")) {
                  console.log("ğŸ§  DeepSeek-Reasoner å“åº”æ•°æ®:", {
                    fullParsed: parsed,
                    choices: parsed.choices,
                    delta: parsed.choices?.[0]?.delta,
                    deltaKeys: parsed.choices?.[0]?.delta
                      ? Object.keys(parsed.choices[0].delta)
                      : [],
                  });
                }

                const deltaContent = parsed.choices?.[0]?.delta?.content || "";

                if (deltaContent) {
                  fullMarkdown += deltaContent;
                  // å®æ—¶è½¬æ¢ä¸ºHTML
                  fullContent =
                    markdownConverter.convertStreamChunk(fullMarkdown);

                  // æ£€æµ‹æ˜¯å¦ä»æ€ç»´é˜¶æ®µåˆ‡æ¢åˆ°å›å¤é˜¶æ®µ
                  if (
                    hasStartedThinking &&
                    !hasStartedAnswering &&
                    deltaContent.trim()
                  ) {
                    // ç¬¬ä¸€æ¬¡æ”¶åˆ°contentå†…å®¹æ—¶ï¼Œåˆ‡æ¢åˆ°å›å¤é˜¶æ®µ
                    hasStartedAnswering = true;
                    const answeringAiData: AICustomProperties["ai"] = {
                      generated: false,
                      model: options.model || "deepseek-reasoner",
                      provider: "deepseek",
                      generatedAt: new Date().toISOString(),
                      prompt: options.prompt,
                      requestId: `req_${Date.now()}`,
                      showThinking: true,
                      thinkingCollapsed: true,
                      isStreaming: true,
                      originalMarkdown: fullMarkdown,
                      // æ–°å¢ï¼šåˆ‡æ¢åˆ°å›å¤é˜¶æ®µ
                      generationPhase: AIGenerationPhase.ANSWERING, // æœ€ç»ˆç­”æ¡ˆç”Ÿæˆé˜¶æ®µ
                      isThinkingPhase: false, // æ€ç»´é“¾ç”Ÿæˆå·²å®Œæˆ
                      isAnsweringPhase: true, // æ­£åœ¨æœ€ç»ˆç­”æ¡ˆç”Ÿæˆé˜¶æ®µ
                      thinkingChain: {
                        steps: [
                          {
                            id: "thinking_complete",
                            content: fullReasoning,
                            timestamp: Date.now(),
                          },
                        ],
                        summary: `æ€è€ƒè¿‡ç¨‹å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå›å¤ (${fullReasoning.length}å­—ç¬¦)`,
                        totalSteps: 1,
                      },
                    };

                    console.log(
                      "ğŸ”„ åˆ‡æ¢åˆ°å›å¤é˜¶æ®µï¼Œæ€ç»´é“¾å†…å®¹é•¿åº¦:",
                      fullReasoning.length
                    );
                    options.onStream?.(fullContent, answeringAiData);
                  } else {
                    // æ™®é€šçš„contentæ›´æ–°
                    options.onStream?.(fullContent);
                  }
                }

                // è§£ææ€ç»´é“¾å†…å®¹ - DeepSeek Reasonerçš„æ€ç»´é“¾æ•°æ®
                // æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå¯èƒ½çš„å­—æ®µååŒ…æ‹¬ï¼šreasoning_content, reasoning, thinking
                const delta = parsed.choices?.[0]?.delta;
                let reasoning = null;

                if (delta && options.model?.includes("reasoner")) {
                  reasoning =
                    delta.reasoning_content || // DeepSeekå®˜æ–¹å­—æ®µå
                    delta.reasoning || // å¯èƒ½çš„å­—æ®µå
                    delta.thinking || // å¦ä¸€ç§å¯èƒ½
                    delta.thought || // å¤‡é€‰å­—æ®µå
                    delta["reasoning-content"]; // å¯èƒ½ä½¿ç”¨è¿å­—ç¬¦

                  // ç´¯ç§¯å®Œæ•´çš„reasoningå†…å®¹ï¼Œä¸è¦ä¸ºæ¯ä¸ªç‰‡æ®µåˆ›å»ºç‹¬ç«‹æ­¥éª¤
                  if (reasoning) {
                    fullReasoning += reasoning;

                    // ç¬¬ä¸€æ¬¡æ”¶åˆ°reasoningæ—¶ï¼Œç«‹å³æ˜¾ç¤ºæ€ç»´é“¾å®¹å™¨
                    if (!hasStartedThinking) {
                      hasStartedThinking = true;
                      console.log("ğŸ§  å¼€å§‹æ€è€ƒè¿‡ç¨‹ï¼Œç«‹å³æ˜¾ç¤ºæ€ç»´é“¾å®¹å™¨");

                      // åˆ›å»ºåˆå§‹çš„æ€ç»´é“¾æ•°æ®å¹¶é€šè¿‡onStreamå›è°ƒ
                      const initialAiData: AICustomProperties["ai"] = {
                        generated: false, // æ ‡è®°ä¸ºæ­£åœ¨ç”Ÿæˆä¸­
                        model: options.model || "deepseek-reasoner",
                        provider: "deepseek",
                        generatedAt: new Date().toISOString(),
                        prompt: options.prompt,
                        requestId: `req_${Date.now()}`,
                        showThinking: true,
                        thinkingCollapsed: true,
                        isStreaming: true, // æ ‡è®°ä¸ºæµå¼ç”Ÿæˆä¸­
                        originalMarkdown: "",
                        // æ–°å¢ï¼šç”Ÿæˆé˜¶æ®µçŠ¶æ€
                        generationPhase: AIGenerationPhase.THINKING, // æ€ç»´é“¾ç”Ÿæˆé˜¶æ®µ
                        isThinkingPhase: true, // æ­£åœ¨æ€ç»´é“¾ç”Ÿæˆé˜¶æ®µ
                        isAnsweringPhase: false, // å°šæœªè¿›å…¥æœ€ç»ˆç­”æ¡ˆç”Ÿæˆé˜¶æ®µ
                        thinkingChain: {
                          steps: [
                            {
                              id: "thinking_in_progress",
                              content: "æ­£åœ¨æ€è€ƒä¸­...",
                              timestamp: Date.now(),
                            },
                          ],
                          summary: "æ€è€ƒè¿‡ç¨‹è¿›è¡Œä¸­",
                          totalSteps: 1,
                        },
                      };

                      // é€šè¿‡onStreamç«‹å³æ˜¾ç¤ºæ€ç»´é“¾å®¹å™¨
                      options.onStream?.("", initialAiData);
                    }

                    // å®æ—¶æ›´æ–°æ€ç»´é“¾å†…å®¹
                    if (hasStartedThinking) {
                      const updatedAiData: AICustomProperties["ai"] = {
                        generated: false,
                        model: options.model || "deepseek-reasoner",
                        provider: "deepseek",
                        generatedAt: new Date().toISOString(),
                        prompt: options.prompt,
                        requestId: `req_${Date.now()}`,
                        showThinking: true,
                        thinkingCollapsed: true,
                        isStreaming: true,
                        originalMarkdown: fullMarkdown,
                        // æ–°å¢ï¼šç”Ÿæˆé˜¶æ®µçŠ¶æ€
                        generationPhase: AIGenerationPhase.THINKING, // ä»åœ¨æ€ç»´é“¾ç”Ÿæˆé˜¶æ®µ
                        isThinkingPhase: true, // æ­£åœ¨æ€ç»´é“¾ç”Ÿæˆé˜¶æ®µ
                        isAnsweringPhase: false, // å°šæœªè¿›å…¥æœ€ç»ˆç­”æ¡ˆç”Ÿæˆé˜¶æ®µ
                        thinkingChain: {
                          steps: [
                            {
                              id: "thinking_live",
                              content: fullReasoning,
                              timestamp: Date.now(),
                            },
                          ],
                          summary: `æ€è€ƒè¿‡ç¨‹è¿›è¡Œä¸­ (${fullReasoning.length}å­—ç¬¦)`,
                          totalSteps: 1,
                        },
                      };

                      // å®æ—¶æ›´æ–°æ€ç»´é“¾å†…å®¹
                      options.onStream?.(fullMarkdown, updatedAiData);
                    }

                    // åªåœ¨ç¬¬ä¸€æ¬¡æ”¶åˆ°reasoningæ—¶è®°å½•è°ƒè¯•ä¿¡æ¯
                    if (fullReasoning.length === reasoning.length) {
                      console.log("ğŸ§  å¼€å§‹æ”¶é›†æ€ç»´é“¾å†…å®¹:", {
                        fieldName: Object.keys(delta).find(
                          (key) =>
                            key.includes("reason") || key.includes("think")
                        ),
                        initialContent: reasoning.substring(0, 50) + "...",
                      });
                    }
                  }
                }

                // è®°å½•è°ƒè¯•æ•°æ® - ä¼ é€’å•ä¸ªreasoningç‰‡æ®µç”¨äºè°ƒè¯•ï¼Œä½†ä¸åˆ›å»ºç‹¬ç«‹æ­¥éª¤
                aiDebugCollector.recordStreamChunk(
                  debugSessionId,
                  parsed,
                  deltaContent,
                  reasoning // è¿™é‡Œä¼ é€’ç‰‡æ®µï¼Œä½†è°ƒè¯•æ”¶é›†å™¨éœ€è¦ä¿®æ”¹å¤„ç†é€»è¾‘
                );

                retryCount = 0; // é‡ç½®é‡è¯•è®¡æ•°
              } catch (parseError) {
                console.warn(
                  "è§£æDeepSeekå“åº”æ•°æ®å¤±è´¥:",
                  parseError,
                  "åŸå§‹æ•°æ®:",
                  data
                );
                retryCount++;
                if (retryCount > maxRetries) {
                  throw new Error("è¿ç»­è§£æå¤±è´¥ï¼Œä¸­æ­¢ç”Ÿæˆ");
                }
              }
            }
          }
        } catch (readError) {
          if (readError instanceof Error && readError.name === "AbortError") {
            return;
          }
          console.error("è¯»å–DeepSeekæµæ•°æ®å¤±è´¥:", readError);
          retryCount++;
          if (retryCount > maxRetries) {
            throw readError;
          }
          // çŸ­æš‚å»¶è¿Ÿåç»§ç»­
          await new Promise((resolve) => setTimeout(resolve, 100));
        }
      }

      if (!abortController.signal.aborted) {
        // æœ€ç»ˆè½¬æ¢
        const finalHTML = markdownConverter.convertComplete(fullMarkdown);

        // æ„é€ AIæ•°æ®
        const aiData: AICustomProperties["ai"] = {
          generated: true,
          model: options.model || "deepseek-chat",
          provider: "deepseek",
          generatedAt: new Date().toISOString(),
          prompt: options.prompt,
          requestId: `req_${Date.now()}`,
          showThinking:
            options.model?.includes("reasoner") && thinkingChain.length > 0,
          thinkingCollapsed: false,
          isStreaming: false,
          originalMarkdown: fullMarkdown,
          // æ–°å¢ï¼šæœ€ç»ˆå®ŒæˆçŠ¶æ€
          generationPhase: AIGenerationPhase.COMPLETED, // ç”Ÿæˆå®Œæˆé˜¶æ®µ
          isThinkingPhase: false, // æ€ç»´é“¾ç”Ÿæˆå·²å®Œæˆ
          isAnsweringPhase: false, // æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå·²å®Œæˆ
        };

        // å¦‚æœæ˜¯reasoneræ¨¡å‹ä¸”æœ‰å®Œæ•´çš„reasoningå†…å®¹
        if (options.model?.includes("reasoner") && fullReasoning.trim()) {
          // å°†å®Œæ•´çš„reasoningä½œä¸ºä¸€ä¸ªæ€ç»´é“¾æ­¥éª¤ï¼Œè€Œä¸æ˜¯å¤šä¸ªç¢ç‰‡
          const completeThinkingStep = {
            id: "reasoning_complete",
            content: fullReasoning.trim(),
            timestamp: Date.now(),
          };

          console.log("ğŸ§  æ„é€ å®Œæ•´æ€ç»´é“¾æ•°æ®:", {
            model: options.model,
            reasoningLength: fullReasoning.length,
            reasoningPreview: fullReasoning.substring(0, 100) + "...",
            totalSteps: 1,
          });

          aiData.thinkingChain = {
            steps: [completeThinkingStep],
            summary: `å®Œæ•´æ€è€ƒè¿‡ç¨‹ (${fullReasoning.length}å­—ç¬¦)`,
            totalSteps: 1,
          };
        } else {
          console.log("âš ï¸ æœªæ„é€ æ€ç»´é“¾æ•°æ®:", {
            model: options.model,
            isReasonerModel: options.model?.includes("reasoner"),
            reasoningLength: fullReasoning?.length || 0,
            showThinking: aiData.showThinking,
          });
        }

        console.log("ğŸ¯ æœ€ç»ˆAIæ•°æ®:", {
          model: aiData.model,
          provider: aiData.provider,
          hasThinkingChain: !!aiData.thinkingChain,
          showThinking: aiData.showThinking,
          thinkingSteps: aiData.thinkingChain?.totalSteps || 0,
        });

        // è®°å½•è°ƒè¯•å®Œæˆæ•°æ®
        aiDebugCollector.completeSession(debugSessionId, finalHTML, aiData);

        options.onComplete?.(finalHTML, aiData);
      }
    } finally {
      reader.releaseLock();
    }
  }
}

/**
 * é˜¿é‡Œç™¾ç‚¼ æä¾›å•†å®ç°
 */
class AlibabaProvider implements AIProvider {
  name = "alibaba";
  supportedModels = ["qwen-plus", "qwen-turbo", "qwen-max"];
  supportsStreaming = true;
  supportsThinking = false; // æš‚æ—¶ä¸æ”¯æŒæ€ç»´é“¾ï¼Œå¾…å®˜æ–¹APIæ›´æ–°

  async generateContent(options: AIGenerationOptions): Promise<void> {
    const securityManager = SecurityManager.getInstance();
    const apiKey = await securityManager.getAPIKey("alibaba");

    if (!apiKey) {
      throw new Error("é˜¿é‡Œç™¾ç‚¼ APIå¯†é’¥æœªé…ç½®");
    }

    try {
      const response = await fetch(
        "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: options.model || "qwen-turbo",
            input: {
              messages: [
                {
                  role: "user",
                  content: options.prompt,
                },
              ],
            },
            parameters: {
              temperature: options.temperature || 0.7,
              max_tokens: options.maxTokens || 2000,
              stream: true,
            },
          }),
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(
          `é˜¿é‡Œç™¾ç‚¼ APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}. ${errorText}`
        );
      }

      // ç®€åŒ–çš„æµå¼å¤„ç†
      const reader = response.body?.getReader();
      if (!reader) throw new Error("æ— æ³•è¯»å–å“åº”æµ");

      let fullMarkdown = "";

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = new TextDecoder().decode(value);
          const content = this.extractContentFromChunk(chunk);
          if (content) {
            fullMarkdown += content;
            const html = markdownConverter.convertStreamChunk(fullMarkdown);
            options.onStream?.(html);
          }
        }

        const finalHTML = markdownConverter.convertComplete(fullMarkdown);
        const aiData: AICustomProperties["ai"] = {
          generated: true,
          model: options.model || "qwen-turbo",
          provider: "alibaba",
          generatedAt: new Date().toISOString(),
          prompt: options.prompt,
          requestId: `req_${Date.now()}`,
          showThinking: false, // ä¸æ”¯æŒæ€ç»´é“¾
          thinkingCollapsed: true,
          isStreaming: false,
          originalMarkdown: fullMarkdown,
        };

        options.onComplete?.(finalHTML, aiData);
      } finally {
        reader.releaseLock();
      }
    } catch (error) {
      console.error("é˜¿é‡Œç™¾ç‚¼ APIè°ƒç”¨å¤±è´¥:", error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  private extractContentFromChunk(chunk: string): string {
    try {
      const lines = chunk
        .split("\n")
        .filter((line) => line.startsWith("data: "));
      let content = "";
      for (const line of lines) {
        const data = line.slice(6);
        if (data === "[DONE]") continue;
        const parsed = JSON.parse(data);
        // é˜¿é‡Œç™¾ç‚¼å¯èƒ½ä½¿ç”¨ä¸åŒçš„å­—æ®µç»“æ„
        content +=
          parsed.output?.choices?.[0]?.message?.content ||
          parsed.output?.text ||
          "";
      }
      return content;
    } catch {
      return "";
    }
  }
}

/**
 * ç¡…åŸºæµåŠ¨ æä¾›å•†å®ç°ï¼ˆä½¿ç”¨OpenAIå…¼å®¹APIï¼‰
 */
class SiliconFlowProvider implements AIProvider {
  name = "siliconflow";
  supportedModels = ["deepseek-chat", "qwen-72b-chat", "internlm2_5-7b-chat"];
  supportsStreaming = true;
  supportsThinking = false; // ä½œä¸ºä»£ç†æœåŠ¡ï¼Œä¸æ”¯æŒæ€ç»´é“¾

  async generateContent(options: AIGenerationOptions): Promise<void> {
    const securityManager = SecurityManager.getInstance();
    const apiKey = await securityManager.getAPIKey("siliconflow");

    if (!apiKey) {
      throw new Error("ç¡…åŸºæµåŠ¨ APIå¯†é’¥æœªé…ç½®");
    }

    try {
      const response = await fetch(
        "https://api.siliconflow.cn/v1/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: options.model || "deepseek-chat",
            messages: [
              {
                role: "user",
                content: options.prompt,
              },
            ],
            stream: true,
            temperature: options.temperature || 0.7,
            max_tokens: options.maxTokens || 2000,
          }),
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(
          `ç¡…åŸºæµåŠ¨ APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}. ${errorText}`
        );
      }

      // ä½¿ç”¨OpenAIå…¼å®¹çš„æµå¼å¤„ç†
      const reader = response.body?.getReader();
      if (!reader) throw new Error("æ— æ³•è¯»å–å“åº”æµ");

      let fullMarkdown = "";

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = new TextDecoder().decode(value);
          const content = this.extractContentFromChunk(chunk);
          if (content) {
            fullMarkdown += content;
            const html = markdownConverter.convertStreamChunk(fullMarkdown);
            options.onStream?.(html);
          }
        }

        const finalHTML = markdownConverter.convertComplete(fullMarkdown);
        const aiData: AICustomProperties["ai"] = {
          generated: true,
          model: options.model || "deepseek-chat",
          provider: "siliconflow",
          generatedAt: new Date().toISOString(),
          prompt: options.prompt,
          requestId: `req_${Date.now()}`,
          showThinking: false, // ä¸æ”¯æŒæ€ç»´é“¾
          thinkingCollapsed: true,
          isStreaming: false,
          originalMarkdown: fullMarkdown,
        };

        options.onComplete?.(finalHTML, aiData);
      } finally {
        reader.releaseLock();
      }
    } catch (error) {
      console.error("ç¡…åŸºæµåŠ¨ APIè°ƒç”¨å¤±è´¥:", error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  private extractContentFromChunk(chunk: string): string {
    try {
      const lines = chunk
        .split("\n")
        .filter((line) => line.startsWith("data: "));
      let content = "";
      for (const line of lines) {
        const data = line.slice(6);
        if (data === "[DONE]") continue;
        const parsed = JSON.parse(data);
        content += parsed.choices?.[0]?.delta?.content || "";
      }
      return content;
    } catch {
      return "";
    }
  }
}

/**
 * Anthropic æä¾›å•†å®ç°
 */
class AnthropicProvider implements AIProvider {
  name = "anthropic";
  supportedModels = ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"];
  supportsStreaming = true;
  supportsThinking = false; // Claudeæš‚æ—¶ä¸æ”¯æŒæ€ç»´é“¾

  async generateContent(options: AIGenerationOptions): Promise<void> {
    const securityManager = SecurityManager.getInstance();
    const apiKey = await securityManager.getAPIKey("anthropic");

    if (!apiKey) {
      throw new Error("Anthropic APIå¯†é’¥æœªé…ç½®");
    }

    try {
      const response = await fetch("https://api.anthropic.com/v1/messages", {
        method: "POST",
        headers: {
          "x-api-key": apiKey,
          "Content-Type": "application/json",
          "anthropic-version": "2023-06-01",
        },
        body: JSON.stringify({
          model: options.model || "claude-3-sonnet-20240229",
          messages: [
            {
              role: "user",
              content: options.prompt,
            },
          ],
          stream: true,
          temperature: options.temperature || 0.7,
          max_tokens: options.maxTokens || 2000,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(
          `Anthropic APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}. ${errorText}`
        );
      }

      // Claudeçš„æµå¼å¤„ç†
      const reader = response.body?.getReader();
      if (!reader) throw new Error("æ— æ³•è¯»å–å“åº”æµ");

      let fullMarkdown = "";

      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = new TextDecoder().decode(value);
          const content = this.extractContentFromChunk(chunk);
          if (content) {
            fullMarkdown += content;
            const html = markdownConverter.convertStreamChunk(fullMarkdown);
            options.onStream?.(html);
          }
        }

        const finalHTML = markdownConverter.convertComplete(fullMarkdown);
        const aiData: AICustomProperties["ai"] = {
          generated: true,
          model: options.model || "claude-3-sonnet",
          provider: "anthropic",
          generatedAt: new Date().toISOString(),
          prompt: options.prompt,
          requestId: `req_${Date.now()}`,
          showThinking: false, // ä¸æ”¯æŒæ€ç»´é“¾
          thinkingCollapsed: true,
          isStreaming: false,
          originalMarkdown: fullMarkdown,
        };

        options.onComplete?.(finalHTML, aiData);
      } finally {
        reader.releaseLock();
      }
    } catch (error) {
      console.error("Anthropic APIè°ƒç”¨å¤±è´¥:", error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  private extractContentFromChunk(chunk: string): string {
    try {
      const lines = chunk
        .split("\n")
        .filter((line) => line.startsWith("data: "));
      let content = "";
      for (const line of lines) {
        const data = line.slice(6);
        if (data === "[DONE]") continue;
        const parsed = JSON.parse(data);
        // Anthropicä½¿ç”¨ä¸åŒçš„å­—æ®µç»“æ„
        content += parsed.delta?.text || "";
      }
      return content;
    } catch {
      return "";
    }
  }
}

/**
 * AI æœåŠ¡ä¸»ç±»
 */
class AIService {
  private providers: Map<string, AIProvider> = new Map();
  private currentProvider: string = "zhipu";
  private securityManager: SecurityManager;
  private currentSettings: AISettings = {
    provider: "zhipu",
    apiKeys: {},
    defaultModel: "",
    temperature: 0.7,
    maxTokens: 1000,
    showThinking: true,
    autoSave: true,
  };

  constructor() {
    this.securityManager = SecurityManager.getInstance();
    this.initializeProviders();
    // å¼‚æ­¥åŠ è½½ç”¨æˆ·è®¾ç½®ï¼Œä¸é˜»å¡æ„é€ å‡½æ•°
    this.loadUserSettings().catch((error: any) =>
      console.error("åˆå§‹åŒ–æ—¶åŠ è½½AIè®¾ç½®å¤±è´¥:", error)
    );
  }

  private initializeProviders() {
    // æ™ºè°±AIæä¾›å•†
    this.providers.set("zhipu", new ZhipuAIProvider());

    // DeepSeekæä¾›å•†
    this.providers.set("deepseek", new DeepSeekProvider());

    // OpenAIæä¾›å•†
    this.providers.set("openai", new OpenAIProvider());

    // é˜¿é‡Œç™¾ç‚¼æä¾›å•†
    this.providers.set("alibaba", new AlibabaProvider());

    // ç¡…åŸºæµåŠ¨æä¾›å•†
    this.providers.set("siliconflow", new SiliconFlowProvider());

    // Anthropicæä¾›å•†
    this.providers.set("anthropic", new AnthropicProvider());
  }

  /**
   * åŠ è½½ç”¨æˆ·ä¿å­˜çš„AIé…ç½®ï¼ˆä»IndexedDBï¼‰
   */
  private async loadUserSettings(): Promise<void> {
    try {
      // é¦–å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦ä»localStorageè¿ç§»æ•°æ®
      await dbOperations.migrateAIConfigsFromLocalStorage();

      // ä»IndexedDBåŠ è½½AIè®¾ç½®
      const settingsConfig = await dbOperations.getAIConfig("ai_settings");
      if (settingsConfig && settingsConfig.value) {
        const parsed = JSON.parse(settingsConfig.value);

        // æ›´æ–°å®Œæ•´çš„è®¾ç½®
        this.currentSettings = {
          ...this.currentSettings,
          ...parsed,
        };

        // åŠ è½½ç”¨æˆ·é…ç½®çš„æä¾›å•†
        if (parsed.provider && this.providers.has(parsed.provider)) {
          this.currentProvider = parsed.provider;
          this.currentSettings.provider = parsed.provider;
          console.log(`ğŸ“‹ å·²åŠ è½½ç”¨æˆ·é…ç½®çš„AIæä¾›å•†: ${this.currentProvider}`);
        }

        // åŠ è½½ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
        if (parsed.defaultModel) {
          this.currentSettings.defaultModel = parsed.defaultModel;
          console.log(`ğŸ“‹ å·²åŠ è½½ç”¨æˆ·é…ç½®çš„é»˜è®¤æ¨¡å‹: ${parsed.defaultModel}`);
        } else {
          // å¦‚æœæ²¡æœ‰ä¿å­˜çš„æ¨¡å‹ï¼Œä½¿ç”¨å½“å‰æä¾›å•†çš„ç¬¬ä¸€ä¸ªæ¨¡å‹
          this.currentSettings.defaultModel =
            this.providers.get(this.currentProvider)?.supportedModels[0] || "";
        }
      } else {
        // å¦‚æœæ²¡æœ‰ä¿å­˜çš„è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        this.currentSettings.defaultModel =
          this.providers.get(this.currentProvider)?.supportedModels[0] || "";
      }
    } catch (error) {
      console.error("åŠ è½½ç”¨æˆ·AIè®¾ç½®å¤±è´¥:", error);
      // ä¿æŒé»˜è®¤è®¾ç½®
      this.currentSettings.defaultModel =
        this.providers.get(this.currentProvider)?.supportedModels[0] || "";
    }
  }

  /**
   * ç”Ÿæˆä¾¿ç­¾å†…å®¹
   */
  async generateNote(options: AIGenerationOptions): Promise<void> {
    try {
      const provider = this.providers.get(this.currentProvider);
      if (!provider) {
        throw new Error(`AIæä¾›å•† ${this.currentProvider} ä¸å¯ç”¨`);
      }

      // ç¡®ä¿optionsåŒ…å«å®Œæ•´çš„é…ç½®ä¿¡æ¯
      const completeOptions: AIGenerationOptions = {
        ...options,
        // å¦‚æœæ²¡æœ‰æŒ‡å®šmodelï¼Œä½¿ç”¨å½“å‰è®¾ç½®çš„é»˜è®¤æ¨¡å‹
        model:
          options.model ||
          this.currentSettings.defaultModel ||
          provider.supportedModels[0] ||
          "unknown",
        // å¦‚æœæ²¡æœ‰æŒ‡å®šå…¶ä»–å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
        temperature: options.temperature ?? this.currentSettings.temperature,
        maxTokens: options.maxTokens ?? this.currentSettings.maxTokens,
      };

      console.log(
        `ğŸš€ ä½¿ç”¨ ${provider.name} å¼€å§‹ç”Ÿæˆå†…å®¹ï¼Œæ¨¡å‹: ${
          completeOptions.model
        }ï¼Œæç¤º: ${completeOptions.prompt.slice(0, 50)}...`
      );

      await provider.generateContent(completeOptions);
    } catch (error) {
      console.error("AIç”Ÿæˆå¤±è´¥:", error);
      options.onError?.(error as Error);
      throw error;
    }
  }

  /**
   * è®¾ç½®AIæä¾›å•†
   */
  setProvider(providerName: string): void {
    if (this.providers.has(providerName)) {
      this.currentProvider = providerName;
      this.currentSettings.provider = providerName;
      console.log(`ğŸ”„ åˆ‡æ¢AIæä¾›å•†: ${providerName}`);
    } else {
      throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${providerName}`);
    }
  }

  /**
   * è·å–å½“å‰æä¾›å•†
   */
  getCurrentProvider(): string {
    return this.currentProvider;
  }

  /**
   * è·å–å¯ç”¨æä¾›å•†åˆ—è¡¨
   */
  getAvailableProviders(): string[] {
    return Array.from(this.providers.keys());
  }

  /**
   * è·å–æä¾›å•†ä¿¡æ¯
   */
  getProviderInfo(providerName: string): AIProvider | undefined {
    return this.providers.get(providerName);
  }

  /**
   * æ£€æŸ¥æä¾›å•†æ˜¯å¦é…ç½®å®Œæˆï¼ˆå¼‚æ­¥ï¼‰
   */
  async isProviderConfigured(providerName: string): Promise<boolean> {
    const apiKey = await this.securityManager.getAPIKey(providerName);
    return !!apiKey;
  }

  /**
   * é…ç½®æä¾›å•†APIå¯†é’¥ï¼ˆå¼‚æ­¥ï¼‰
   */
  async configureProvider(providerName: string, apiKey: string): Promise<void> {
    if (!this.providers.has(providerName)) {
      throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${providerName}`);
    }

    if (!this.securityManager.validateAPIKey(providerName, apiKey)) {
      throw new Error(`æ— æ•ˆçš„APIå¯†é’¥æ ¼å¼: ${providerName}`);
    }

    await this.securityManager.setAPIKey(providerName, apiKey);
    console.log(`âœ… ${providerName} APIå¯†é’¥é…ç½®æˆåŠŸ`);
  }

  /**
   * æµ‹è¯•æä¾›å•†è¿æ¥
   */
  async testProvider(providerName: string): Promise<boolean> {
    try {
      const provider = this.providers.get(providerName);
      if (!provider) {
        throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${providerName}`);
      }

      const apiKey = await this.securityManager.getAPIKey(providerName);
      if (!apiKey) {
        throw new Error("APIå¯†é’¥æœªé…ç½®");
      }

      // å‘é€æµ‹è¯•è¯·æ±‚
      const testPrompt = "æµ‹è¯•è¿æ¥";
      let testEndpoint = "";
      let testHeaders = {};
      let testBody = {};

      switch (providerName) {
        case "zhipu":
          testEndpoint =
            "https://open.bigmodel.cn/api/paas/v4/chat/completions";
          testHeaders = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          };
          testBody = {
            model: "glm-4-flash",
            messages: [{ role: "user", content: testPrompt }],
            max_tokens: 10,
          };
          break;
        case "deepseek":
          testEndpoint = "https://api.deepseek.com/v1/chat/completions";
          testHeaders = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          };
          testBody = {
            model: "deepseek-chat",
            messages: [{ role: "user", content: testPrompt }],
            max_tokens: 10,
          };
          break;
        case "openai":
          testEndpoint = "https://api.openai.com/v1/chat/completions";
          testHeaders = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          };
          testBody = {
            model: "gpt-3.5-turbo",
            messages: [{ role: "user", content: testPrompt }],
            max_tokens: 10,
          };
          break;
        case "alibaba":
          testEndpoint =
            "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation";
          testHeaders = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          };
          testBody = {
            model: "qwen-turbo",
            input: {
              messages: [{ role: "user", content: testPrompt }],
            },
            parameters: {
              max_tokens: 10,
            },
          };
          break;
        case "siliconflow":
          testEndpoint = "https://api.siliconflow.cn/v1/chat/completions";
          testHeaders = {
            Authorization: `Bearer ${apiKey}`,
            "Content-Type": "application/json",
          };
          testBody = {
            model: "deepseek-chat",
            messages: [{ role: "user", content: testPrompt }],
            max_tokens: 10,
          };
          break;
        case "anthropic":
          testEndpoint = "https://api.anthropic.com/v1/messages";
          testHeaders = {
            "x-api-key": apiKey,
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01",
          };
          testBody = {
            model: "claude-3-haiku-20240307",
            messages: [{ role: "user", content: testPrompt }],
            max_tokens: 10,
          };
          break;
        default:
          return false;
      }

      const response = await fetch(testEndpoint, {
        method: "POST",
        headers: testHeaders,
        body: JSON.stringify(testBody),
      });

      return response.ok;
    } catch (error) {
      console.error(`${providerName} è¿æ¥æµ‹è¯•å¤±è´¥:`, error);
      return false;
    }
  }

  /**
   * è·å–AIè®¾ç½®ï¼ˆä»IndexedDBå¼‚æ­¥åŠ è½½ï¼‰
   */
  async getSettings(): Promise<AISettings> {
    const settings: AISettings = {
      provider: this.currentProvider,
      apiKeys: {},
      defaultModel:
        this.providers.get(this.currentProvider)?.supportedModels[0] || "",
      temperature: 0.7,
      maxTokens: 1000,
      showThinking: true,
      autoSave: true,
    };

    // ä»IndexedDBåŠ è½½å…¶ä»–è®¾ç½®
    try {
      const settingsConfig = await dbOperations.getAIConfig("ai_settings");
      if (settingsConfig && settingsConfig.value) {
        const parsed = JSON.parse(settingsConfig.value);
        Object.assign(settings, parsed);
      }
    } catch (error) {
      console.error("åŠ è½½AIè®¾ç½®å¤±è´¥:", error);
    }

    return settings;
  }

  /**
   * åŒæ­¥è·å–AIè®¾ç½®ï¼ˆè¿”å›å·²åŠ è½½çš„è®¾ç½®ï¼‰
   */
  getSettingsSync(): AISettings {
    return {
      ...this.currentSettings,
      provider: this.currentProvider,
      // å¦‚æœæ²¡æœ‰é»˜è®¤æ¨¡å‹ï¼Œä½¿ç”¨å½“å‰æä¾›å•†çš„ç¬¬ä¸€ä¸ªæ¨¡å‹
      defaultModel:
        this.currentSettings.defaultModel ||
        this.providers.get(this.currentProvider)?.supportedModels[0] ||
        "",
    };
  }

  /**
   * ä¿å­˜AIè®¾ç½®ï¼ˆå¼‚æ­¥ä¿å­˜åˆ°IndexedDBï¼‰
   */
  async saveSettings(settings: Partial<AISettings>): Promise<void> {
    try {
      // ä¿å­˜APIå¯†é’¥åˆ°ç‹¬ç«‹å­˜å‚¨
      if (settings.apiKeys) {
        for (const [provider, key] of Object.entries(settings.apiKeys)) {
          if (key) {
            await this.configureProvider(provider, key);
          }
        }
      }

      // æ›´æ–°å†…å­˜ä¸­çš„è®¾ç½®
      this.currentSettings = {
        ...this.currentSettings,
        ...settings,
      };

      // æ›´æ–°å½“å‰æä¾›å•†
      if (settings.provider && settings.provider !== this.currentProvider) {
        this.currentProvider = settings.provider;
        this.currentSettings.provider = settings.provider;
      }

      // ä¿å­˜å…¶ä»–è®¾ç½®åˆ°IndexedDB
      const settingsToSave = { ...settings };
      delete settingsToSave.apiKeys; // ä¸ä¿å­˜æ˜æ–‡å¯†é’¥

      const config: AIConfigDB = {
        id: "ai_settings",
        type: "settings",
        value: JSON.stringify(settingsToSave),
        encrypted: false,
        createdAt: new Date(),
        updatedAt: new Date(),
      };

      await dbOperations.saveAIConfig(config);

      console.log("âœ… AIè®¾ç½®ä¿å­˜æˆåŠŸ:", settingsToSave);
    } catch (error) {
      console.error("ä¿å­˜AIè®¾ç½®å¤±è´¥:", error);
      throw error;
    }
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const aiService = new AIService();

// å¯¼å‡ºå®‰å…¨ç®¡ç†å™¨å®ä¾‹
export const securityManager = SecurityManager.getInstance();

// å¯¼å‡ºç±»å’Œæ¥å£
export { AIService, ZhipuAIProvider, OpenAIProvider };
